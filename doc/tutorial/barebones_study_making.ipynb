{
 "metadata": {
  "name": "",
  "signature": "sha256:5cbcc236ac3f35e9bf8c75196a3f3137a12c2551fd1d9a0c7aa2f57b3ee93178"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Create a barebones datapackage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we begin, let's import everything we need."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the flotilla package for biological data analysis\n",
      "import flotilla\n",
      "\n",
      "# Import \"numerical python\" library for number crunching\n",
      "import numpy as np\n",
      "\n",
      "# Import \"panel data analysis\" library for tabular data\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Shalek and Satija, *et al* (2013)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "In the 2013 paper, [Single-cell transcriptomics reveals bimodality in expression and splicing in immune cells](http://www.ncbi.nlm.nih.gov/pubmed/23685454) (Shalek and Satija, *et al*. *Nature* (2013)), Regev and colleagues performed single-cell sequencing 18 bone marrow-derived dendritic cells (BMDCs), in addition to 3 pooled samples.\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Expression data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we will read in the expression data. These data were obtained using,\n",
      "\n",
      "    wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE41nnn/GSE41265/suppl/GSE41265_allGenesTPM.txt.gz\n",
      "\n",
      "We will also compare to the supplementary table 2 data, obtained using\n",
      "\n",
      "    wget http://www.nature.com/nature/journal/v498/n7453/extref/nature12172-s1.zip\n",
      "    unzip nature12172-s1.zip"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expression = pd.read_table(\"GSE41265_allGenesTPM.txt.gz\", compression=\"gzip\", index_col=0)\n",
      "expression.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>S1</th>\n",
        "      <th>S2</th>\n",
        "      <th>S3</th>\n",
        "      <th>S4</th>\n",
        "      <th>S5</th>\n",
        "      <th>S6</th>\n",
        "      <th>S7</th>\n",
        "      <th>S8</th>\n",
        "      <th>S9</th>\n",
        "      <th>S10</th>\n",
        "      <th>...</th>\n",
        "      <th>S12</th>\n",
        "      <th>S13</th>\n",
        "      <th>S14</th>\n",
        "      <th>S15</th>\n",
        "      <th>S16</th>\n",
        "      <th>S17</th>\n",
        "      <th>S18</th>\n",
        "      <th>P1</th>\n",
        "      <th>P2</th>\n",
        "      <th>P3</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>GENE</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>XKR4</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.019906</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AB338584</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>B3GAT2</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.023441</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.029378</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.055452</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.029448</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.031654</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>42.150208</td>\n",
        "      <td>0.680327</td>\n",
        "      <td>0.022996</td>\n",
        "      <td>0.110236</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>NPL</th>\n",
        "      <td>72.008590</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>128.062012</td>\n",
        "      <td>0.095082</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>112.310234</td>\n",
        "      <td>104.329122</td>\n",
        "      <td>0.119230</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.116802</td>\n",
        "      <td>0.104200</td>\n",
        "      <td>0.106188</td>\n",
        "      <td>0.229197</td>\n",
        "      <td>0.110582</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>7.109356</td>\n",
        "      <td>6.727028</td>\n",
        "      <td>14.525447</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>T2</th>\n",
        "      <td>0.109249</td>\n",
        "      <td>0.172009</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.182703</td>\n",
        "      <td>0.076012</td>\n",
        "      <td>0.078698</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.093698</td>\n",
        "      <td>0.076583</td>\n",
        "      <td>...</td>\n",
        "      <td>0.693459</td>\n",
        "      <td>0.010137</td>\n",
        "      <td>0.081936</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.086879</td>\n",
        "      <td>0.068174</td>\n",
        "      <td>0.062063</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.050605</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 21 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "                 S1        S2          S3        S4        S5        S6  \\\n",
        "GENE                                                                      \n",
        "XKR4       0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
        "AB338584   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
        "B3GAT2     0.000000  0.000000    0.023441  0.000000  0.000000  0.029378   \n",
        "NPL       72.008590  0.000000  128.062012  0.095082  0.000000  0.000000   \n",
        "T2         0.109249  0.172009    0.000000  0.000000  0.182703  0.076012   \n",
        "\n",
        "                  S7          S8        S9       S10    ...           S12  \\\n",
        "GENE                                                    ...                 \n",
        "XKR4        0.000000    0.000000  0.000000  0.000000    ...      0.000000   \n",
        "AB338584    0.000000    0.000000  0.000000  0.000000    ...      0.000000   \n",
        "B3GAT2      0.000000    0.055452  0.000000  0.029448    ...      0.000000   \n",
        "NPL       112.310234  104.329122  0.119230  0.000000    ...      0.000000   \n",
        "T2          0.078698    0.000000  0.093698  0.076583    ...      0.693459   \n",
        "\n",
        "               S13       S14       S15       S16       S17        S18  \\\n",
        "GENE                                                                    \n",
        "XKR4      0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
        "AB338584  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
        "B3GAT2    0.000000  0.031654  0.000000  0.000000  0.000000  42.150208   \n",
        "NPL       0.116802  0.104200  0.106188  0.229197  0.110582   0.000000   \n",
        "T2        0.010137  0.081936  0.000000  0.000000  0.086879   0.068174   \n",
        "\n",
        "                P1        P2         P3  \n",
        "GENE                                     \n",
        "XKR4      0.000000  0.019906   0.000000  \n",
        "AB338584  0.000000  0.000000   0.000000  \n",
        "B3GAT2    0.680327  0.022996   0.110236  \n",
        "NPL       7.109356  6.727028  14.525447  \n",
        "T2        0.062063  0.000000   0.050605  \n",
        "\n",
        "[5 rows x 21 columns]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These data are in the \"transcripts per million,\" aka TPM unit. See [this](http://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) blog post if that sounds weird to you."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These data are formatted with samples on the columns, and genes on the rows. But we want the opposite, with samples on the rows and genes on the columns. This follows [`scikit-learn`](http://scikit-learn.org/stable/tutorial/basic/tutorial.html#loading-an-example-dataset)'s standard of data matrices with size (`n_samples`, `n_features`) as each gene is a feature. So we will simply transpose this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expression = expression.T\n",
      "expression.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>GENE</th>\n",
        "      <th>XKR4</th>\n",
        "      <th>AB338584</th>\n",
        "      <th>B3GAT2</th>\n",
        "      <th>NPL</th>\n",
        "      <th>T2</th>\n",
        "      <th>T</th>\n",
        "      <th>PDE10A</th>\n",
        "      <th>1700010I14RIK</th>\n",
        "      <th>6530411M01RIK</th>\n",
        "      <th>PABPC6</th>\n",
        "      <th>...</th>\n",
        "      <th>AK085062</th>\n",
        "      <th>DHX9</th>\n",
        "      <th>RNASET2B</th>\n",
        "      <th>FGFR1OP</th>\n",
        "      <th>CCR6</th>\n",
        "      <th>BRP44L</th>\n",
        "      <th>AK014435</th>\n",
        "      <th>AK015714</th>\n",
        "      <th>SFT2D1</th>\n",
        "      <th>PRR18</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S1</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>72.008590</td>\n",
        "      <td>0.109249</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0.774638</td>\n",
        "      <td>23.520936</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0</td>\n",
        "      <td>460.316773</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>39.442566</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.172009</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0.367391</td>\n",
        "      <td>1.887873</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0</td>\n",
        "      <td>823.890290</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>4.967412</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S3</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.023441</td>\n",
        "      <td>128.062012</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0.249858</td>\n",
        "      <td>0.313510</td>\n",
        "      <td>0.166772</td>\n",
        "      <td>0</td>\n",
        "      <td>1002.354241</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S4</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.095082</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0.354157</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.887003</td>\n",
        "      <td>0</td>\n",
        "      <td>1230.766795</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.131215</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S5</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.182703</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0.039263</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>131.077131</td>\n",
        "      <td>0</td>\n",
        "      <td>1614.749122</td>\n",
        "      <td>0</td>\n",
        "      <td>0.242179</td>\n",
        "      <td>95.485743</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 27723 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "GENE  XKR4  AB338584    B3GAT2         NPL        T2  T  PDE10A  \\\n",
        "S1       0         0  0.000000   72.008590  0.109249  0       0   \n",
        "S2       0         0  0.000000    0.000000  0.172009  0       0   \n",
        "S3       0         0  0.023441  128.062012  0.000000  0       0   \n",
        "S4       0         0  0.000000    0.095082  0.000000  0       0   \n",
        "S5       0         0  0.000000    0.000000  0.182703  0       0   \n",
        "\n",
        "GENE  1700010I14RIK  6530411M01RIK  PABPC6  ...    AK085062      DHX9  \\\n",
        "S1                0              0       0  ...           0  0.774638   \n",
        "S2                0              0       0  ...           0  0.367391   \n",
        "S3                0              0       0  ...           0  0.249858   \n",
        "S4                0              0       0  ...           0  0.354157   \n",
        "S5                0              0       0  ...           0  0.039263   \n",
        "\n",
        "GENE   RNASET2B     FGFR1OP  CCR6       BRP44L  AK014435  AK015714     SFT2D1  \\\n",
        "S1    23.520936    0.000000     0   460.316773         0  0.000000  39.442566   \n",
        "S2     1.887873    0.000000     0   823.890290         0  0.000000   4.967412   \n",
        "S3     0.313510    0.166772     0  1002.354241         0  0.000000   0.000000   \n",
        "S4     0.000000    0.887003     0  1230.766795         0  0.000000   0.131215   \n",
        "S5     0.000000  131.077131     0  1614.749122         0  0.242179  95.485743   \n",
        "\n",
        "GENE  PRR18  \n",
        "S1        0  \n",
        "S2        0  \n",
        "S3        0  \n",
        "S4        0  \n",
        "S5        0  \n",
        "\n",
        "[5 rows x 27723 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The authors filtered the expression data based on having at least 3 single cells express genes with at TPM (transcripts per million, ) > 1. We can express this in using the [`pandas`](http://pandas.pydata.org) DataFrames easily.\n",
      "\n",
      "First, from reading the paper and looking at the data, I know there are 18 single cells, and there are 18 samples that start with the letter \"S.\" So I will extract the single samples from the `index` (row names) using a `lambda`, a tiny function which in this case, tells me whether or not that sample id begins with the letter \"S\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "singles_ids = expression.index[expression.index.map(lambda x: x.startswith('S'))]\n",
      "print('number of single cells:', len(singles_ids))\n",
      "singles = expression.ix[singles_ids]\n",
      "\n",
      "expression_filtered = expression.ix[:, singles[singles > 1].count() >= 3]\n",
      "expression_filtered = np.log(expression_filtered + 1)\n",
      "expression_filtered.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('number of single cells:', 18)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(21, 6312)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmm, that's strange. The paper states that they had 6313 genes after filtering, but I get 6312. Even using \"`singles >= 1`\" doesn't help.\n",
      "\n",
      "(I also tried this with the expression table provided in the supplementary data as \"`SupplementaryTable2.xlsx`,\" and got the same results.)\n",
      "\n",
      "Now that we've taken care of importing and filtering the expression data, let's do the feature data of the expression data.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Expression feature data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n",
      "This is similar to the `fData` from `BioconductoR`, where there's some additional data on your features that you want to look at. They uploaded information about the features in their OTHER expression matrix, uploaded as a supplementary file, `Supplementary_Table2.xlsx`.\n",
      "\n",
      "Notice that this is a `csv` and not an `xlsx`. This is because Excel mangled the gene IDS that started with `201*` and assumed they were dates :(\n",
      "\n",
      "The workaround I did was to add another column to the sheet with the formula `=\"'\" & A1`, press `Command`-`Shift`-`End` to select the end of the rows, and then do `Ctrl`-`D` to \"fill down\" to the bottom (thanks to [this](http://superuser.com/questions/298276/excel-keyboard-shortcut-to-copy-fill-down-for-all-cells-with-non-blank-adjacent) stackoverflow post for teaching me how to Excel). Then, I saved the file as a `csv` for maximum portability and compatibility."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expression2 = pd.read_csv('nature12172-s1/Supplementary_Table2.csv', \n",
      "                            # Need to specify the index column as both the first and the last columns,\n",
      "                            # Because the last column is the \"Gene Category\"\n",
      "                            index_col=[0, -1], parse_dates=False, infer_datetime_format=False)\n",
      "\n",
      "# This was also in features x samples format, so we need to transpose\n",
      "expression2 = expression2.T\n",
      "expression2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "File nature12172-s1/Supplementary_Table2.csv does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-623c304ac226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                             \u001b[0;31m# Need to specify the index column as both the first and the last columns,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0;31m# Because the last column is the \"Gene Category\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                             index_col=[0, -1], parse_dates=False, infer_datetime_format=False)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# This was also in features x samples format, so we need to transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    468\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3163)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5779)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: File nature12172-s1/Supplementary_Table2.csv does not exist"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to strip the single-quote I added to all the gene names:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_index, indexer = expression2.columns.reindex(map(lambda x: (x[0].lstrip(\"'\"), x[1]), expression2.columns.values))\n",
      "expression2.columns = new_index\n",
      "expression2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to create a `pandas.DataFrame` from the \"Gene Category\" row for our `expression_feature_data`, which we will do via:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gene_ids, gene_category = zip(*expression2.columns.values)\n",
      "gene_categories = pd.Series(gene_category, index=gene_ids, name='gene_category')\n",
      "gene_categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expression_feature_data = pd.DataFrame(gene_categories)\n",
      "expression_feature_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Splicing Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We obtain the splicing data from this study from the supplementary information, specifically the `Supplementary_Table4.xls`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "splicing = pd.read_excel('nature12172-s1/Supplementary_Table4.xls', 'splicingTable.txt', index_col=(0,1))\n",
      "splicing.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "splicing = splicing.T\n",
      "splicing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The three pooled samples aren't named consistently with the expression data, so we have to fix that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "splicing.index[splicing.index.map(lambda x: 'P' in x)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the pooled sample IDs are inconsistent with the `expression` data, we have to change them. We can get the \"P\" and the number after that using regular expressions, called `re` in the Python standard library, e.g.:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "re.search(r'P\\d', '10,000 cell Rep1 (P1)').group()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def long_pooled_name_to_short(x):\n",
      "    if 'P' not in x:\n",
      "        return x\n",
      "    else:\n",
      "        return re.search(r'P\\d', x).group()\n",
      "\n",
      "\n",
      "splicing.index.map(long_pooled_name_to_short)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we assign this new index as our index to the `splicing` dataframe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "splicing.index = splicing.index.map(long_pooled_name_to_short)\n",
      "splicing.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Metadata\n",
      "\n",
      "Now let's get into creating a metadata dataframe. We'll use the index from the `expression_filtered` data to create the minimum required column, `'phenotype'`, which has the name of the phenotype of that cell. And we'll also add the column `'pooled'` to indicate whether this sample is pooled or not."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata = pd.DataFrame(index=expression_filtered.index)\n",
      "metadata['phenotype'] = 'BDMC'\n",
      "metadata['pooled'] = metadata.index.map(lambda x: x.startswith('P'))\n",
      "\n",
      "metadata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Mapping stats data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapping_stats = pd.read_excel('nature12172-s1/Supplementary_Table1.xls', sheetname='SuppTable1 2.txt')\n",
      "mapping_stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create a `flotilla` Study!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "study = flotilla.Study(# The metadata describing phenotype and pooled samples\n",
      "                       metadata, \n",
      "                       \n",
      "                       # A version for this data\n",
      "                       version='0.1.0', \n",
      "                       \n",
      "                       # Dataframe of the filtered expression data\n",
      "                       expression_data=expression_filtered,\n",
      "                       \n",
      "                       # Dataframe of the feature data of the genes\n",
      "                       expression_feature_data=expression_feature_data,\n",
      "                       \n",
      "                       # Dataframe of the splicing data\n",
      "                       splicing_data=splicing, \n",
      "                       \n",
      "                       # Dataframe of the mapping stats data\n",
      "                       mapping_stats_data=mapping_stats, \n",
      "                       \n",
      "                       # Which column in \"mapping_stats\" has the number of reads\n",
      "                       mapping_stats_number_mapped_col='PF_READS')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a side note, you can save this study to disk now, so you can \"`embark`\" later:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "study.save('shalek2013')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that this is saved to my home directory, in `~/flotilla_projects/<study_name>/`. This will be saved in your home directory, too.\n",
      "\n",
      "The `datapackage.json` file is what holds all the information relative to the study, and loosely follows the [datapackage spec](http://data.okfn.org/doc/data-package) created by the Open Knowledge Foundation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat /Users/olga/flotilla_projects/shalek2013/datapackage.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One thing to note is that when you save, the version number is bumped up. `study.version` (the one we just made) is `0.1.0`, but the one we saved is `0.1.1`, since we could have made some changes to the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Let's look at what else is in this folder:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls /Users/olga/flotilla_projects/shalek2013"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So this is where all the other files are. Good to know!\n",
      "\n",
      "We can \"embark\" on this newly-saved study now very painlessly, without having to open and process all those files again:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "study2 = flotilla.embark('shalek2013')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}