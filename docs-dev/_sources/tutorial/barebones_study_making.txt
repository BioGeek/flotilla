
Create a barebones datapackage
==============================

Before we begin, let's import everything we need.

.. code:: python

    # Import the flotilla package for biological data analysis
    import flotilla
    
    # Import "numerical python" library for number crunching
    import numpy as np
    
    # Import "panel data analysis" library for tabular data
    import pandas as pd
Shalek and Satija, *et al* (2013)
---------------------------------

In the 2013 paper, `Single-cell transcriptomics reveals bimodality in
expression and splicing in immune
cells <http://www.ncbi.nlm.nih.gov/pubmed/23685454>`_ (Shalek and
Satija, *et al*. *Nature* (2013)), Regev and colleagues performed
single-cell sequencing 18 bone marrow-derived dendritic cells (BMDCs),
in addition to 3 pooled samples.

Expression data
---------------

First, we will read in the expression data. These data were obtained
using,

::

    wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE41nnn/GSE41265/suppl/GSE41265_allGenesTPM.txt.gz

We will also compare to the supplementary table 2 data, obtained using

::

    wget http://www.nature.com/nature/journal/v498/n7453/extref/nature12172-s1.zip
    unzip nature12172-s1.zip

.. code:: python

    expression = pd.read_table("GSE41265_allGenesTPM.txt.gz", compression="gzip", index_col=0)
    expression.head()

::


    ---------------------------------------------------------------------------
    IOError                                   Traceback (most recent call last)

    <ipython-input-2-b45e9120e279> in <module>()
    ----> 1 expression = pd.read_table("GSE41265_allGenesTPM.txt.gz", compression="gzip", index_col=0)
          2 expression.head()


    /home/travis/miniconda/envs/testenv/lib/python2.7/site-packages/pandas/io/parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)
        468                     skip_blank_lines=skip_blank_lines)
        469 
    --> 470         return _read(filepath_or_buffer, kwds)
        471 
        472     parser_f.__name__ = name


    /home/travis/miniconda/envs/testenv/lib/python2.7/site-packages/pandas/io/parsers.pyc in _read(filepath_or_buffer, kwds)
        244 
        245     # Create the parser.
    --> 246     parser = TextFileReader(filepath_or_buffer, **kwds)
        247 
        248     if (nrows is not None) and (chunksize is not None):


    /home/travis/miniconda/envs/testenv/lib/python2.7/site-packages/pandas/io/parsers.pyc in __init__(self, f, engine, **kwds)
        560             self.options['has_index_names'] = kwds['has_index_names']
        561 
    --> 562         self._make_engine(self.engine)
        563 
        564     def _get_options_with_defaults(self, engine):


    /home/travis/miniconda/envs/testenv/lib/python2.7/site-packages/pandas/io/parsers.pyc in _make_engine(self, engine)
        697     def _make_engine(self, engine='c'):
        698         if engine == 'c':
    --> 699             self._engine = CParserWrapper(self.f, **self.options)
        700         else:
        701             if engine == 'python':


    /home/travis/miniconda/envs/testenv/lib/python2.7/site-packages/pandas/io/parsers.pyc in __init__(self, src, **kwds)
       1064         kwds['allow_leading_cols'] = self.index_col is not False
       1065 
    -> 1066         self._reader = _parser.TextReader(src, **kwds)
       1067 
       1068         # XXX


    /home/travis/miniconda/envs/testenv/lib/python2.7/site-packages/pandas/parser.so in pandas.parser.TextReader.__cinit__ (pandas/parser.c:3163)()


    /home/travis/miniconda/envs/testenv/lib/python2.7/site-packages/pandas/parser.so in pandas.parser.TextReader._setup_parser_source (pandas/parser.c:5335)()


    /home/travis/miniconda/envs/testenv/lib/python2.7/gzip.pyc in __init__(self, filename, mode, compresslevel, fileobj, mtime)
         92             mode += 'b'
         93         if fileobj is None:
    ---> 94             fileobj = self.myfileobj = __builtin__.open(filename, mode or 'rb')
         95         if filename is None:
         96             # Issue #13781: os.fdopen() creates a fileobj with a bogus name


    IOError: [Errno 2] No such file or directory: 'GSE41265_allGenesTPM.txt.gz'


These data are in the "transcripts per million," aka TPM unit. See
`this <http://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/>`_
blog post if that sounds weird to you.

These data are formatted with samples on the columns, and genes on the
rows. But we want the opposite, with samples on the rows and genes on
the columns. This follows
```scikit-learn`` <http://scikit-learn.org/stable/tutorial/basic/tutorial.html#loading-an-example-dataset>`_'s
standard of data matrices with size (``n_samples``, ``n_features``) as
each gene is a feature. So we will simply transpose this.

.. code:: python

    expression = expression.T
    expression.head()



.. raw:: html

    <div style="max-height:1000px;max-width:1500px;overflow:auto;">
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th>GENE</th>
          <th>XKR4</th>
          <th>AB338584</th>
          <th>B3GAT2</th>
          <th>NPL</th>
          <th>T2</th>
          <th>T</th>
          <th>PDE10A</th>
          <th>1700010I14RIK</th>
          <th>6530411M01RIK</th>
          <th>PABPC6</th>
          <th>...</th>
          <th>AK085062</th>
          <th>DHX9</th>
          <th>RNASET2B</th>
          <th>FGFR1OP</th>
          <th>CCR6</th>
          <th>BRP44L</th>
          <th>AK014435</th>
          <th>AK015714</th>
          <th>SFT2D1</th>
          <th>PRR18</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>S1</th>
          <td>0</td>
          <td>0</td>
          <td>0.000000</td>
          <td>72.008590</td>
          <td>0.109249</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>...</td>
          <td>0</td>
          <td>0.774638</td>
          <td>23.520936</td>
          <td>0.000000</td>
          <td>0</td>
          <td>460.316773</td>
          <td>0</td>
          <td>0.000000</td>
          <td>39.442566</td>
          <td>0</td>
        </tr>
        <tr>
          <th>S2</th>
          <td>0</td>
          <td>0</td>
          <td>0.000000</td>
          <td>0.000000</td>
          <td>0.172009</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>...</td>
          <td>0</td>
          <td>0.367391</td>
          <td>1.887873</td>
          <td>0.000000</td>
          <td>0</td>
          <td>823.890290</td>
          <td>0</td>
          <td>0.000000</td>
          <td>4.967412</td>
          <td>0</td>
        </tr>
        <tr>
          <th>S3</th>
          <td>0</td>
          <td>0</td>
          <td>0.023441</td>
          <td>128.062012</td>
          <td>0.000000</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>...</td>
          <td>0</td>
          <td>0.249858</td>
          <td>0.313510</td>
          <td>0.166772</td>
          <td>0</td>
          <td>1002.354241</td>
          <td>0</td>
          <td>0.000000</td>
          <td>0.000000</td>
          <td>0</td>
        </tr>
        <tr>
          <th>S4</th>
          <td>0</td>
          <td>0</td>
          <td>0.000000</td>
          <td>0.095082</td>
          <td>0.000000</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>...</td>
          <td>0</td>
          <td>0.354157</td>
          <td>0.000000</td>
          <td>0.887003</td>
          <td>0</td>
          <td>1230.766795</td>
          <td>0</td>
          <td>0.000000</td>
          <td>0.131215</td>
          <td>0</td>
        </tr>
        <tr>
          <th>S5</th>
          <td>0</td>
          <td>0</td>
          <td>0.000000</td>
          <td>0.000000</td>
          <td>0.182703</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>...</td>
          <td>0</td>
          <td>0.039263</td>
          <td>0.000000</td>
          <td>131.077131</td>
          <td>0</td>
          <td>1614.749122</td>
          <td>0</td>
          <td>0.242179</td>
          <td>95.485743</td>
          <td>0</td>
        </tr>
      </tbody>
    </table>
    <p>5 rows Ã— 27723 columns</p>
    </div>



The authors filtered the expression data based on having at least 3
single cells express genes with at TPM (transcripts per million, ) > 1.
We can express this in using the
```pandas`` <http://pandas.pydata.org>`_ DataFrames easily.

First, from reading the paper and looking at the data, I know there are
18 single cells, and there are 18 samples that start with the letter
"S." So I will extract the single samples from the ``index`` (row names)
using a ``lambda``, a tiny function which in this case, tells me whether
or not that sample id begins with the letter "S".

.. code:: python

    singles_ids = expression.index[expression.index.map(lambda x: x.startswith('S'))]
    print('number of single cells:', len(singles_ids))
    singles = expression.ix[singles_ids]
    
    expression_filtered = expression.ix[:, singles[singles > 1].count() >= 3]
    expression_filtered = np.log(expression_filtered + 1)
    expression_filtered.shape

.. parsed-literal::

    ('number of single cells:', 18)




.. parsed-literal::

    (21, 6312)



Hmm, that's strange. The paper states that they had 6313 genes after
filtering, but I get 6312. Even using "``singles >= 1``" doesn't help.

(I also tried this with the expression table provided in the
supplementary data as "``SupplementaryTable2.xlsx``," and got the same
results.)

Now that we've taken care of importing and filtering the expression
data, let's do the feature data of the expression data.

Expression feature data
-----------------------

This is similar to the ``fData`` from ``BioconductoR``, where there's
some additional data on your features that you want to look at. They
uploaded information about the features in their OTHER expression
matrix, uploaded as a supplementary file, ``Supplementary_Table2.xlsx``.

Notice that this is a ``csv`` and not an ``xlsx``. This is because Excel
mangled the gene IDS that started with ``201*`` and assumed they were
dates :(

The workaround I did was to add another column to the sheet with the
formula ``="'" & A1``, press ``Command``-``Shift``-``End`` to select the
end of the rows, and then do ``Ctrl``-``D`` to "fill down" to the bottom
(thanks to
`this <http://superuser.com/questions/298276/excel-keyboard-shortcut-to-copy-fill-down-for-all-cells-with-non-blank-adjacent>`_
stackoverflow post for teaching me how to Excel). Then, I saved the file
as a ``csv`` for maximum portability and compatibility.

.. code:: python

    expression2 = pd.read_csv('nature12172-s1/Supplementary_Table2.csv', 
                                # Need to specify the index column as both the first and the last columns,
                                # Because the last column is the "Gene Category"
                                index_col=[0, -1], parse_dates=False, infer_datetime_format=False)
    
    # This was also in features x samples format, so we need to transpose
    expression2 = expression2.T
    expression2.head()

::


    ---------------------------------------------------------------------------
    IOError                                   Traceback (most recent call last)

    <ipython-input-5-623c304ac226> in <module>()
          2                             # Need to specify the index column as both the first and the last columns,
          3                             # Because the last column is the "Gene Category"
    ----> 4                             index_col=[0, -1], parse_dates=False, infer_datetime_format=False)
          5 
          6 # This was also in features x samples format, so we need to transpose


    /Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc in parser_f(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)
        468                     skip_blank_lines=skip_blank_lines)
        469 
    --> 470         return _read(filepath_or_buffer, kwds)
        471 
        472     parser_f.__name__ = name


    /Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc in _read(filepath_or_buffer, kwds)
        244 
        245     # Create the parser.
    --> 246     parser = TextFileReader(filepath_or_buffer, **kwds)
        247 
        248     if (nrows is not None) and (chunksize is not None):


    /Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc in __init__(self, f, engine, **kwds)
        560             self.options['has_index_names'] = kwds['has_index_names']
        561 
    --> 562         self._make_engine(self.engine)
        563 
        564     def _get_options_with_defaults(self, engine):


    /Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc in _make_engine(self, engine)
        697     def _make_engine(self, engine='c'):
        698         if engine == 'c':
    --> 699             self._engine = CParserWrapper(self.f, **self.options)
        700         else:
        701             if engine == 'python':


    /Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/io/parsers.pyc in __init__(self, src, **kwds)
       1064         kwds['allow_leading_cols'] = self.index_col is not False
       1065 
    -> 1066         self._reader = _parser.TextReader(src, **kwds)
       1067 
       1068         # XXX


    /Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/parser.so in pandas.parser.TextReader.__cinit__ (pandas/parser.c:3163)()


    /Users/olga/anaconda/envs/flotilla_docs/lib/python2.7/site-packages/pandas/parser.so in pandas.parser.TextReader._setup_parser_source (pandas/parser.c:5779)()


    IOError: File nature12172-s1/Supplementary_Table2.csv does not exist


Now we need to strip the single-quote I added to all the gene names:

.. code:: python

    new_index, indexer = expression2.columns.reindex(map(lambda x: (x[0].lstrip("'"), x[1]), expression2.columns.values))
    expression2.columns = new_index
    expression2.head()
We want to create a ``pandas.DataFrame`` from the "Gene Category" row
for our ``expression_feature_data``, which we will do via:

.. code:: python

    gene_ids, gene_category = zip(*expression2.columns.values)
    gene_categories = pd.Series(gene_category, index=gene_ids, name='gene_category')
    gene_categories
.. code:: python

    expression_feature_data = pd.DataFrame(gene_categories)
    expression_feature_data.head()
Splicing Data
-------------

We obtain the splicing data from this study from the supplementary
information, specifically the ``Supplementary_Table4.xls``

.. code:: python

    splicing = pd.read_excel('nature12172-s1/Supplementary_Table4.xls', 'splicingTable.txt', index_col=(0,1))
    splicing.head()
.. code:: python

    splicing = splicing.T
    splicing
The three pooled samples aren't named consistently with the expression
data, so we have to fix that.

.. code:: python

    splicing.index[splicing.index.map(lambda x: 'P' in x)]
Since the pooled sample IDs are inconsistent with the ``expression``
data, we have to change them. We can get the "P" and the number after
that using regular expressions, called ``re`` in the Python standard
library, e.g.:

.. code:: python

    import re
    re.search(r'P\d', '10,000 cell Rep1 (P1)').group()
.. code:: python

    def long_pooled_name_to_short(x):
        if 'P' not in x:
            return x
        else:
            return re.search(r'P\d', x).group()
    
    
    splicing.index.map(long_pooled_name_to_short)
And now we assign this new index as our index to the ``splicing``
dataframe

.. code:: python

    splicing.index = splicing.index.map(long_pooled_name_to_short)
    splicing.head()
Metadata
--------

Now let's get into creating a metadata dataframe. We'll use the index
from the ``expression_filtered`` data to create the minimum required
column, ``'phenotype'``, which has the name of the phenotype of that
cell. And we'll also add the column ``'pooled'`` to indicate whether
this sample is pooled or not.

.. code:: python

    metadata = pd.DataFrame(index=expression_filtered.index)
    metadata['phenotype'] = 'BDMC'
    metadata['pooled'] = metadata.index.map(lambda x: x.startswith('P'))
    
    metadata
Mapping stats data
------------------

.. code:: python

    mapping_stats = pd.read_excel('nature12172-s1/Supplementary_Table1.xls', sheetname='SuppTable1 2.txt')
    mapping_stats
Create a ``flotilla`` Study!
----------------------------

.. code:: python

    study = flotilla.Study(# The metadata describing phenotype and pooled samples
                           metadata, 
                           
                           # A version for this data
                           version='0.1.0', 
                           
                           # Dataframe of the filtered expression data
                           expression_data=expression_filtered,
                           
                           # Dataframe of the feature data of the genes
                           expression_feature_data=expression_feature_data,
                           
                           # Dataframe of the splicing data
                           splicing_data=splicing, 
                           
                           # Dataframe of the mapping stats data
                           mapping_stats_data=mapping_stats, 
                           
                           # Which column in "mapping_stats" has the number of reads
                           mapping_stats_number_mapped_col='PF_READS')
As a side note, you can save this study to disk now, so you can
"``embark``" later:

.. code:: python

    study.save('shalek2013')
Note that this is saved to my home directory, in
``~/flotilla_projects/<study_name>/``. This will be saved in your home
directory, too.

The ``datapackage.json`` file is what holds all the information relative
to the study, and loosely follows the `datapackage
spec <http://data.okfn.org/doc/data-package>`_ created by the Open
Knowledge Foundation.

.. code:: python

    cat /Users/olga/flotilla_projects/shalek2013/datapackage.json
One thing to note is that when you save, the version number is bumped
up. ``study.version`` (the one we just made) is ``0.1.0``, but the one
we saved is ``0.1.1``, since we could have made some changes to the
data.

Let's look at what else is in this folder:

.. code:: python

    ls /Users/olga/flotilla_projects/shalek2013
So this is where all the other files are. Good to know!

We can "embark" on this newly-saved study now very painlessly, without
having to open and process all those files again:

.. code:: python

    study2 = flotilla.embark('shalek2013')